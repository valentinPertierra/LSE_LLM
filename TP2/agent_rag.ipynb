{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d738edfa-cab1-496a-b1c1-18b2cf7678a0",
   "metadata": {},
   "source": [
    "<img src=\"logoFIUBA.jpg\" width=\"300\" align=\"right\">\n",
    "\n",
    "\n",
    "# LLMs e IAG\n",
    "## TP N°2 \"RAG con agentes\"\n",
    "\n",
    "Valentín Pertierra\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9210a8-8499-4c70-a6c5-dd7c12abc981",
   "metadata": {},
   "source": [
    "## Carga de datos en base de datos vectorial\n",
    "\n",
    "Se utilizara la base de datos vectorial de Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e9e57-5a02-44b8-af19-f292dc4f24a1",
   "metadata": {},
   "source": [
    "### Procesamiento de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13a0681-dc03-4ebb-bc72-d84cf91921be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9977a46b-3256-4318-b4cc-2287c87d75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero los chunks\n",
    "def chunkData(docs, chunk_size=100, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5625c9c2-860a-4878-9483-4848e1a0b2ec",
   "metadata": {},
   "source": [
    "Se cargaran en la base de datos vectorial dos CVs, el de mio y el de Juan Perez (dummy cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf8604e-c511-476a-ad45-3bd77dd4cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los documentos \n",
    "valentinFilePath = \"cv_valentin_pertierra.pdf\"\n",
    "juanFilePath = \"cv_juan_perez.pdf\"\n",
    "\n",
    "vloader = PyPDFLoader(valentinFilePath)\n",
    "vdocs = vloader.load()\n",
    "\n",
    "jloader = PyPDFLoader(juanFilePath)\n",
    "jdocs = jloader.load()\n",
    "\n",
    "# Genero los chunks \n",
    "vchunks = chunkData(vdocs, chunk_size=500, chunk_overlap=100)\n",
    "jchunks = chunkData(jdocs, chunk_size=500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2bd31-5b04-4bdc-8a07-4af02f086e1a",
   "metadata": {},
   "source": [
    "### Generación de embbeding y carga en base de datos vectorial\n",
    "Se utilizara un indice por cada uno de los cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc532d10-6cd5-46e1-956b-a77287855eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6dd8573-5ecf-460b-9ca8-cbb17381256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41be9cb0-d296-4dbe-98d1-c8d2cc9f1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to DB Pinecone\n",
    "pc=Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "cloud = 'aws'\n",
    "region = 'us-east-1'\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "\n",
    "indices = ['vagent', 'jagent']\n",
    "namespace = \"espacio\"\n",
    "dimension = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73a8ebbe-ddb5-4c5b-8885-850c370df084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raglse']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes().names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3bfce94-c977-4120-9af6-f6a4ce60537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index creado con el nombre: vagent\n",
      "index creado con el nombre: jagent\n"
     ]
    }
   ],
   "source": [
    "# Elimino el indice si es que ya existe en la base de datos\n",
    "for index_name in indices:\n",
    "    if index_name in pc.list_indexes().names():\n",
    "      pc.delete_index(index_name)\n",
    "      print(\"index {} borrado\".format(index_name))\n",
    "    \n",
    "    if index_name not in pc.list_indexes().names():\n",
    "        # Como lo borre en el paso anterior siempre deberia entrar aca\n",
    "        print(\"index creado con el nombre: {}\".format(index_name))\n",
    "        pc.create_index(\n",
    "            index_name,\n",
    "            dimension=dimension, \n",
    "            metric='cosine',\n",
    "            spec=spec\n",
    "            )\n",
    "    else:\n",
    "        print(\"el index con el nombre {} ya estaba creado\".format(index_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3075029-aa98-4b1b-8c75-df90ab08c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10984\\1365815625.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# Cargo un modelo de embeddings compatible\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e2ec3d1-f0ff-4178-bd68-090202ae7c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upserted values to jagent index\n"
     ]
    }
   ],
   "source": [
    "# Cargo chunks en base de datos\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=vchunks,\n",
    "    index_name='vagent',\n",
    "    embedding=embedding_model, \n",
    "    namespace=namespace\n",
    ")\n",
    "print(\"upserted values to 'vagent' index\")\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ad50f96-4b6f-4e22-b744-b612fe8b71db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upserted values to 'jagent' index\n"
     ]
    }
   ],
   "source": [
    "# Cargo chunks en base de datos\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=jchunks,\n",
    "    index_name='jagent',\n",
    "    embedding=embedding_model, \n",
    "    namespace=namespace\n",
    ")\n",
    "print(\"upserted values to 'jagent' index\")\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe953b8-c08a-4a6d-b2ac-edb1a8bc96db",
   "metadata": {},
   "source": [
    "### Busquedas en base de datos\n",
    "\n",
    "Realizo pruebas para verificar que los datos se guardaron correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b0f7e-d6f7-4fab-a04e-c0294d454a1f",
   "metadata": {},
   "source": [
    "#### Valentin Pertierra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0c878cd-d998-49e0-8d60-b1d02b900806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'espacio': {'vector_count': 10}},\n",
       " 'total_vector_count': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(indices[0])\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64e78205-8240-4610-a6a9-1125930d79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=indices[0],\n",
    "    embedding=embedding_model,\n",
    "    namespace=namespace,\n",
    ")\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8426fd24-c1b0-42bf-b4de-f4a6a5e914fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c2b36f28-7cf7-45db-9cdc-bea1d0fecf31', metadata={'page': 0.0, 'source': 'cv_valentin_pertierra.pdf'}, page_content='PERFIL    _________________________________________  \\n \\nIngeniero en electrónica con experiencia en el desarrollo de \\naplicaciones para la industria 4.0. Considero que tengo constancia y \\nfirmeza para alcanzar los objetivos que me propongo, ideando \\nsoluciones a las dificultades que puedan surgir. Me gusta afrontar \\nnuevos desafíos, buscando siempre aprender y mejorar, tanto en lo \\nhumano, como en lo académico y profesional.  \\n \\n \\n \\n \\n \\nEXPERENCIA LABORAL \\n \\nAnalista de Transformación Digital'),\n",
       " Document(id='23eacb6b-943b-4022-98f5-06b901ed9546', metadata={'page': 0.0, 'source': 'cv_valentin_pertierra.pdf'}, page_content='Cursado hasta el nivel 7 \\n \\nE.T.N°28 “República Francesa”  \\nPromedio 9,34 \\n \\n___________________________________________________________ \\n \\nExamen First Certificate in English  \\nNivel B2 (MCER) acreditado por University of Cambridge ESOL Examinations \\n \\nExamen HSK3  \\nNivel B1 (MCER) acreditado por Hanban \\n \\n__________________________________________________________\\n \\n● Desarrollo de soluciones end to end (diseño, \\nprototipado, implementación, puesta en marcha)'),\n",
       " Document(id='d10705ad-0307-4e9d-a3bd-1c013b06a5a6', metadata={'page': 1.0, 'source': 'cv_valentin_pertierra.pdf'}, page_content='● Diseño y prototipado de circuitos impresos: \\nAltium, KiCad. \\n● Diseño e impresión 3D: Rhinoceros, AutoCAD, \\nslic3r, Pronterface. \\n● Manejo y calibración de impresoras 3D. \\n● Manejo de instrumental de medición: Osciloscopio, \\nanalizador de espectro, analizador vectorial de redes. \\n● Implementación de técnicas de inteligencia artificial: Lógica \\ndifusa, algoritmos genéticos, redes neuronales, visión artificial.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Cuales es su formacion academica?\"\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d90c9a-ecdf-4d61-a458-b70861e24ca8",
   "metadata": {},
   "source": [
    "#### Juan Perez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b270a5c7-3e99-4d6f-8568-a3eed7346c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'espacio': {'vector_count': 10}},\n",
       " 'total_vector_count': 10}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(indices[0])\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b08cdacb-ef12-4f7b-9e1f-899dab38f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvectorstore = PineconeVectorStore(\n",
    "    index_name=indices[1],\n",
    "    embedding=embedding_model,\n",
    "    namespace=namespace,\n",
    ")\n",
    "retriever=jvectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3497870-b84b-42a6-b416-1d452e63f97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='569c9091-edb5-4f33-8153-2a063ec08a9d', metadata={'page': 2.0, 'source': 'cv_juan_perez.pdf'}, page_content='• Aprendí sobre buenas prácticas de desarrollo en entornos empresariales. \\n \\nEducación \\nMaestría en Inteligencia Artificial y Aprendizaje Automático \\nUniversidad de la Innovación \\n2015 - 2017 \\nEspecialización en Ciencia de Datos \\nInstituto Tecnológico Nacional \\n2013 - 2014 \\nLicenciatura en Ingeniería en Sistemas \\nUniversidad Politécnica de Tecnología \\n2007 - 2011 \\nDiplomado en Ciberseguridad \\nAcademia de Tecnología Avanzada \\n2010 \\n \\nProyectos Destacados \\n1. Plataforma de Predicción de Demanda:'),\n",
       " Document(id='c2633fb1-afb2-49ef-8eaa-3f0462f88871', metadata={'page': 0.0, 'source': 'cv_juan_perez.pdf'}, page_content='Información Personal \\nNombre Completo: Juan Pérez Rodríguez \\nDirección: Calle Falsa 123, Ciudad, País \\nTeléfono: +1 234 567 890 \\nCorreo Electrónico: juan.perez@example.com \\nLinkedIn: linkedin.com/in/juan-perez \\nGitHub: github.com/juanperez \\nSitio Web: www.juanperez.com \\n \\nPerfil Profesional \\nIngeniero en Sistemas con más de 15 años de experiencia en desarrollo de software, \\ngestión de proyectos tecnológicos y liderazgo de equipos multidisciplinarios. Experto en'),\n",
       " Document(id='a3c6bc5f-59e2-4a05-a850-d08a4ac03f17', metadata={'page': 2.0, 'source': 'cv_juan_perez.pdf'}, page_content='Creé una plataforma escalable que soporta más de 50,000 usuarios activos al \\nmes. \\n4. Análisis de Opiniones en Redes Sociales: \\nDiseñé un sistema de procesamiento de lenguaje natural (NLP) para extraer \\ninsights de comentarios en tiempo real. \\n5. Dashboards Interactivos: \\nConstruí herramientas visuales utilizando Tableau y Power BI para un cliente del \\nsector financiero. \\n6. Motor de Búsqueda Interna: \\nImplementé ElasticSearch para optimizar el rendimiento de consultas complejas.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Cuales es su educacion o formacion academica?\"\n",
    "jvectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edea2d-fc41-4c4b-a1f6-eed59329529a",
   "metadata": {},
   "source": [
    "## Agente LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c1a0870-1c93-4cd3-a72e-12fbcd4608b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.56-py3-none-any.whl (126 kB)\n",
      "     ------------------------------------ 126.8/126.8 KB 746.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langgraph) (0.3.21)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42\n",
      "  Downloading langgraph_sdk-0.1.43-py3-none-any.whl (31 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.4\n",
      "  Downloading langgraph_checkpoint-2.0.8-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.1.146)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
      "Collecting msgpack<2.0.0,>=1.1.0\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-win_amd64.whl (74 kB)\n",
      "     -------------------------------------- 74.7/74.7 KB 693.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.8.30)\n",
      "Requirement already satisfied: anyio in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.6.2.post1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\dell\\documents\\lse\\llm e ia gen\\tps\\tp1\\ragenv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.2.2)\n",
      "Installing collected packages: msgpack, langgraph-sdk, langgraph-checkpoint, langgraph\n",
      "Successfully installed langgraph-0.2.56 langgraph-checkpoint-2.0.8 langgraph-sdk-0.1.43 msgpack-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\DELL\\Documents\\LSE\\LLM e IA Gen\\tps\\TP1\\ragenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "210c08e0-68b8-4b2a-89c0-58c1a84b2d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygraphviz\n",
      "  Downloading pygraphviz-1.14.tar.gz (106 kB)\n",
      "     -------------------------------------- 106.0/106.0 KB 6.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: pygraphviz\n",
      "  Building wheel for pygraphviz (pyproject.toml): started\n",
      "  Building wheel for pygraphviz (pyproject.toml): finished with status 'error'\n",
      "Failed to build pygraphviz\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for pygraphviz (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [48 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\agraph.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\scraper.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\testing.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\__init__.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  creating build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_close.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_repr_mimebundle.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_scraper.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  running egg_info\n",
      "  writing pygraphviz.egg-info\\PKG-INFO\n",
      "  writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
      "  writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
      "  reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching '*.swg'\n",
      "  warning: no files found matching '*.png' under directory 'doc'\n",
      "  warning: no files found matching '*.html' under directory 'doc'\n",
      "  warning: no files found matching '*.txt' under directory 'doc'\n",
      "  warning: no files found matching '*.css' under directory 'doc'\n",
      "  warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "  no previously-included directories found matching 'doc\\build'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "  copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  running build_ext\n",
      "  building 'pygraphviz._graphviz' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pygraphviz\n",
      "ERROR: Could not build wheels for pygraphviz, which is required to install pyproject.toml-based projects\n",
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\DELL\\Documents\\LSE\\LLM e IA Gen\\tps\\TP1\\ragenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cad56ff5-490d-47af-a661-0854ae7e8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "from langchain.chains import ConversationChain, LLMChain\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1624e699-7d8a-4742-9715-48e17aea6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0766d7b4-ad29-4acb-8eaf-6b522ff6e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    groq_api_key=GROQ_API_KEY, \n",
    "    model_name='llama3-8b-8192'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2af742fa-c7d6-4538-86e4-2207020f9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino una clase para guardar el estado \n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    individual: str\n",
    "    history: List[str] \n",
    "\n",
    "# Defino un tamplate para el prompt\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"individual\"],\n",
    "    template=\"\"\"\n",
    "Eres un asistente para tareas de preguntas y respuestas. Usa los siguientes fragmentos de historia y contexto recuperados para responder la pregunta respecto al individuo.\n",
    "Si no sabes la respuesta, di que no lo sabes. Usa un máximo de 200 palabras y mantén la respuesta concisa. \n",
    "---\n",
    "Historia:\n",
    "{history}\n",
    "---\n",
    "Contexto:\n",
    "{context}\n",
    "---\n",
    "Individuo:\n",
    "{individual}\n",
    "---\n",
    "Pregunta: {question}\n",
    "Respuesta:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Defino una clase agente para hacer la busqueda en la base vectorial segun la persona\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, embedding_model, index=\"\"):\n",
    "        if index==\"\":\n",
    "            raise ValueError(\"No se especifico un índice válido.\")\n",
    "        \n",
    "        self.index = index\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "        self.vectorstore = PineconeVectorStore(\n",
    "            index_name=index,\n",
    "            embedding=self.embedding_model,\n",
    "            namespace=namespace,\n",
    "        )\n",
    "\n",
    "    def get_context(self,state: State):\n",
    "        retrieved_docs = self.vectorstore.similarity_search(state[\"question\"],k=2)\n",
    "        return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "832b4a22-0005-46ad-ace7-cdff1c943310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancio agentes\n",
    "vagent = Agent(embedding_model,\"vagent\")\n",
    "jagent = Agent(embedding_model,\"jagent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5bb6f15d-edce-42d0-a318-b48610cb31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino los nodos para el agente\n",
    "def generate(state: State):\n",
    "    if state[\"context\"]:\n",
    "        docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    else: \n",
    "        docs_content = \"\"\n",
    "    # Formateo la historia como un unico string\n",
    "    history = \"\\n\".join(state[\"history\"])\n",
    "    \n",
    "    # Invoco el prompt con contexto e historia previa\n",
    "    messages = prompt.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": docs_content,\n",
    "        \"individual\": state[\"individual\"],\n",
    "        \"history\": history\n",
    "    })\n",
    "\n",
    "    # print(messages)\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    state[\"history\"].append(f\"Q: {state['question']} A: {response.content}\")\n",
    "    \n",
    "    # Ahora ya es posible devolver la respuesta\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Nodo para limpiar el contexto\n",
    "def empty_context(state:State):\n",
    "    return {\"context\":[]}\n",
    "\n",
    "# Segun sobre a quien se refiere la pregunta se utiliza un agente u otro\n",
    "def decide(state: State):\n",
    "    \n",
    "    leandro_pattern = r\"(Leandro\\sSaraco|Leandro|Saraco)\"\n",
    "    elon_pattern = r\"(Elon\\sMusk|Elon|Musk)\"\n",
    "    individual = \"\" #Default\n",
    "    if re.search(leandro_pattern, state[\"question\"], re.IGNORECASE):\n",
    "        individual = \"leandro\"\n",
    "    elif re.search(elon_pattern, state[\"question\"], re.IGNORECASE):\n",
    "        individual = \"elon\"\n",
    "    return {\"individual\":individual}\n",
    "\n",
    "# Funcion para determinar cuál es el próximo nodo\n",
    "def decision_read_state(state:State):\n",
    "    \"\"\"Obtiene el individuo desde el state y lo retorna para decidir por qué nodo continuar.\"\"\"\n",
    "    indiv = state[\"individual\"]\n",
    "    if indiv==\"\":\n",
    "        print(\"La pregunta no habla de ningun individuo.\")\n",
    "        return \"no_individual\"\n",
    "    print(\"La pregunta habla sobre el individuo:\",indiv)\n",
    "    return indiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd4d0da0-12f0-483c-8e45-537a964026e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armo el grafo de nodos\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"decision\",decide)\n",
    "graph_builder.add_node(\"empty_context\",empty_context)\n",
    "graph_builder.add_node(\"valentin_context\",vagent.get_context)\n",
    "graph_builder.add_node(\"juan_context\",jagent.get_context)\n",
    "graph_builder.add_node(\"generate\",generate)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"decision\",\n",
    "    decision_read_state,\n",
    "    {\"leandro\": \"valentin_context\",\"elon\": \"juan_context\",\"no_individual\":\"empty_context\"}\n",
    "    )\n",
    "graph_builder.add_edge(\"valentin_context\",\"generate\")\n",
    "graph_builder.add_edge(\"juan_context\",\"generate\")\n",
    "graph_builder.add_edge(\"empty_context\",\"generate\")\n",
    "graph_builder.set_entry_point(\"decision\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "335bf711-a809-4c73-aa71-66b35e871f58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Install pygraphviz to draw graphs: `pip install pygraphviz`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\LSE\\LLM e IA Gen\\tps\\TP1\\ragenv\\lib\\site-packages\\langchain_core\\runnables\\graph_png.py:137\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[1;34m(self, graph, output_path)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygraphviz\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 3\u001b[0m Image(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\Documents\\LSE\\LLM e IA Gen\\tps\\TP1\\ragenv\\lib\\site-packages\\langchain_core\\runnables\\graph.py:542\u001b[0m, in \u001b[0;36mGraph.draw_png\u001b[1;34m(self, output_file_path, fontname, labels)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_png\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PngDrawer\n\u001b[0;32m    531\u001b[0m default_node_labels \u001b[38;5;241m=\u001b[39m {node\u001b[38;5;241m.\u001b[39mid: node\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()}\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPngDrawer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfontname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLabelsDict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_node_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnodes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43medges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medges\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 542\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\LSE\\LLM e IA Gen\\tps\\TP1\\ragenv\\lib\\site-packages\\langchain_core\\runnables\\graph_png.py:140\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[1;34m(self, graph, output_path)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    139\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall pygraphviz to draw graphs: `pip install pygraphviz`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Create a directed graph\u001b[39;00m\n\u001b[0;32m    143\u001b[0m viz \u001b[38;5;241m=\u001b[39m pgv\u001b[38;5;241m.\u001b[39mAGraph(directed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nodesep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, ranksep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Install pygraphviz to draw graphs: `pip install pygraphviz`."
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
